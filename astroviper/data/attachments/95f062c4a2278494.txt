WARNING  graphviper:logger.py:109 File exists: [38;2;50;50;205m/home/runner/work/testviper/testviper/src/toolviper/src/toolviper/utils/data/.dropbox[0m
INFO     graphviper:logger.py:55 Updating file metadata information ... 
WARNING  graphviper:logger.py:109 File exists: [38;2;50;50;205m/home/runner/work/testviper/testviper/src/toolviper/src/toolviper/utils/data/.dropbox[0m
INFO     graphviper:logger.py:55 Updating file metadata information ... 
WARNING  graphviper:logger.py:109 File exists: [38;2;50;50;205m/home/runner/work/testviper/testviper/src/toolviper/src/toolviper/utils/data/.dropbox[0m
INFO     graphviper:logger.py:55 Updating file metadata information ... 
INFO     graphviper:logger.py:55 J2000 found as system reference frame in CASA image This corresponds to fk5(equinox="j2000") in astropy. Metadata will be written appropriately
INFO     graphviper:logger.py:55 J2000 found as native reference frame in CASA image This corresponds to fk5(equinox="j2000") in astropy. Metadata will be written appropriately
INFO     graphviper:logger.py:55 J2000 found as system reference frame in CASA image This corresponds to fk5(equinox="j2000") in astropy. Metadata will be written appropriately
INFO     graphviper:logger.py:55 J2000 found as native reference frame in CASA image This corresponds to fk5(equinox="j2000") in astropy. Metadata will be written appropriately
INFO     graphviper:logger.py:55 J2000 found as system reference frame in CASA image This corresponds to fk5(equinox="j2000") in astropy. Metadata will be written appropriately
INFO     graphviper:logger.py:55 J2000 found as native reference frame in CASA image This corresponds to fk5(equinox="j2000") in astropy. Metadata will be written appropriately
INFO     graphviper:parameter.py:227 Module path: [38;2;50;50;205m/home/runner/work/testviper/testviper/src/toolviper[0m
WARNING  graphviper:logger.py:109 It is recommended that the local cache directory be set using the [38;2;50;50;205mdask_local_dir[0m parameter.
INFO     distributed.http.proxy:proxy.py:85 To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
INFO     distributed.scheduler:scheduler.py:1766 State start
INFO     distributed.scheduler:scheduler.py:4282   Scheduler at:     tcp://127.0.0.1:33711
INFO     distributed.scheduler:scheduler.py:4297   dashboard at:  http://127.0.0.1:8787/status
INFO     distributed.scheduler:scheduler.py:8177 Registering Worker plugin shuffle
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:39525'
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:39027 name: 0
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:39027
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:51546
INFO     distributed.scheduler:scheduler.py:1766 State start
INFO     distributed.scheduler:scheduler.py:4282   Scheduler at:     tcp://127.0.0.1:33257
INFO     distributed.scheduler:scheduler.py:4297   dashboard at:  http://127.0.0.1:36797/status
INFO     distributed.scheduler:scheduler.py:8177 Registering Worker plugin shuffle
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:33145'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:44107'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:45473'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:46199'
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:33351 name: 1
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:33351
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:55898
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:35017 name: 0
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:35017
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:55900
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:40285 name: 2
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:40285
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:55914
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:46623 name: 3
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:46623
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:55924
INFO     distributed.scheduler:scheduler.py:5959 Receive client connection: MenrvaClient-2921ad28-5653-11f0-8dc1-6045bd7f8793
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:55940
INFO     distributed.scheduler:scheduler.py:8177 Registering Worker plugin worker_logger
INFO     graphviper:logger.py:55 Client <MenrvaClient: 'tcp://127.0.0.1:33257' processes=4 threads=4, memory=15.62 GiB>
INFO     graphviper:logger.py:55 Time to compute() feather 14.600982189178467s
INFO     distributed.scheduler:scheduler.py:6004 Remove client MenrvaClient-2921ad28-5653-11f0-8dc1-6045bd7f8793
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:55940; closing.
INFO     distributed.scheduler:scheduler.py:6004 Remove client MenrvaClient-2921ad28-5653-11f0-8dc1-6045bd7f8793
INFO     distributed.scheduler:scheduler.py:5996 Close client connection: MenrvaClient-2921ad28-5653-11f0-8dc1-6045bd7f8793
INFO     distributed.scheduler:scheduler.py:7610 Retire worker addresses (stimulus_id='retire-workers-1751357583.9960358') (0, 1, 2, 3)
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:33145'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:44107'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:45473'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:46199'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:55900; closing.
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:55898; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:35017 name: 0 (stimulus_id='handle-worker-cleanup-1751357584.003386')
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:55914; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:33351 name: 1 (stimulus_id='handle-worker-cleanup-1751357584.0046647')
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:40285 name: 2 (stimulus_id='handle-worker-cleanup-1751357584.0058346')
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:55924; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:46623 name: 3 (stimulus_id='handle-worker-cleanup-1751357584.0075717')
INFO     distributed.scheduler:scheduler.py:5583 Lost all workers
INFO     distributed.batched:batched.py:122 Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:33257 remote=tcp://127.0.0.1:55914>
Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
INFO     distributed.batched:batched.py:122 Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:33257 remote=tcp://127.0.0.1:55924>
Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:33257 remote=tcp://127.0.0.1:55924>: Stream is closed
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:46199' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:45473' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:44107' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:33145' closed.
INFO     distributed.scheduler:scheduler.py:4344 Closing scheduler. Reason: unknown
INFO     distributed.scheduler:scheduler.py:4372 Scheduler closing all comms
INFO     graphviper:parameter.py:227 Module path: [38;2;50;50;205m/home/runner/work/testviper/testviper/src/toolviper[0m
WARNING  graphviper:logger.py:109 It is recommended that the local cache directory be set using the [38;2;50;50;205mdask_local_dir[0m parameter.
INFO     distributed.scheduler:scheduler.py:1766 State start
INFO     distributed.scheduler:scheduler.py:4282   Scheduler at:     tcp://127.0.0.1:45117
INFO     distributed.scheduler:scheduler.py:4297   dashboard at:  http://127.0.0.1:42459/status
INFO     distributed.scheduler:scheduler.py:8177 Registering Worker plugin shuffle
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:34591'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:44379'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:39987'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:33153'
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:44075 name: 0
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:44075
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:53746
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:43467 name: 3
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:43467
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:53754
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:34797 name: 2
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:34797
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:53758
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:43895 name: 1
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:43895
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:53760
INFO     distributed.scheduler:scheduler.py:1766 State start
INFO     distributed.scheduler:scheduler.py:4282   Scheduler at:     tcp://127.0.0.1:44231
INFO     distributed.scheduler:scheduler.py:4297   dashboard at:  http://127.0.0.1:33329/status
INFO     distributed.scheduler:scheduler.py:8177 Registering Worker plugin shuffle
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:38293'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:33591'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:43165'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:41465'
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:41595 name: 2
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:41595
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:47750
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:40203 name: 1
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:40203
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:47752
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:41239 name: 3
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:41239
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:47760
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:46391 name: 0
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:46391
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:47762
INFO     distributed.scheduler:scheduler.py:5959 Receive client connection: MenrvaClient-386a5cc4-5653-11f0-8dc1-6045bd7f8793
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:47766
INFO     distributed.scheduler:scheduler.py:8177 Registering Worker plugin worker_logger
INFO     graphviper:logger.py:55 Client <MenrvaClient: 'tcp://127.0.0.1:44231' processes=4 threads=4, memory=15.62 GiB>
INFO     graphviper:logger.py:55 Time to compute() feather 15.495884895324707s
INFO     distributed.scheduler:scheduler.py:6004 Remove client MenrvaClient-386a5cc4-5653-11f0-8dc1-6045bd7f8793
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:47766; closing.
INFO     distributed.scheduler:scheduler.py:6004 Remove client MenrvaClient-386a5cc4-5653-11f0-8dc1-6045bd7f8793
INFO     distributed.scheduler:scheduler.py:5996 Close client connection: MenrvaClient-386a5cc4-5653-11f0-8dc1-6045bd7f8793
INFO     distributed.scheduler:scheduler.py:7610 Retire worker addresses (stimulus_id='retire-workers-1751357610.8906012') (0, 1, 2, 3)
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:38293'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:33591'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:43165'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:41465'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:47762; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:46391 name: 0 (stimulus_id='handle-worker-cleanup-1751357610.8954132')
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:47750; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:41595 name: 2 (stimulus_id='handle-worker-cleanup-1751357610.8985126')
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:47752; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:40203 name: 1 (stimulus_id='handle-worker-cleanup-1751357610.9006338')
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:47760; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:41239 name: 3 (stimulus_id='handle-worker-cleanup-1751357610.902497')
INFO     distributed.scheduler:scheduler.py:5583 Lost all workers
INFO     distributed.batched:batched.py:122 Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:44231 remote=tcp://127.0.0.1:47760>
Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:41465' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:43165' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:38293' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:33591' closed.
INFO     distributed.scheduler:scheduler.py:4344 Closing scheduler. Reason: unknown
INFO     distributed.scheduler:scheduler.py:4372 Scheduler closing all comms