INFO     viperlog:parameter.py:227 Module path: [38;2;50;50;205m/home/runner/work/testviper/testviper/src/toolviper[0m
WARNING  viperlog:logger.py:109 It is recommended that the local cache directory be set using the [38;2;50;50;205mdask_local_dir[0m parameter.
INFO     distributed.scheduler:scheduler.py:1766 State start
INFO     distributed.scheduler:scheduler.py:4282   Scheduler at:     tcp://127.0.0.1:32873
INFO     distributed.scheduler:scheduler.py:4297   dashboard at:  http://127.0.0.1:39433/status
INFO     distributed.scheduler:scheduler.py:8177 Registering Worker plugin shuffle
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:36201'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:36833'
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:40517 name: 1
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:40517
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:37958
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:34169 name: 0
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:34169
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:37968
INFO     distributed.scheduler:scheduler.py:1766 State start
INFO     distributed.scheduler:scheduler.py:4282   Scheduler at:     tcp://127.0.0.1:42659
INFO     distributed.scheduler:scheduler.py:4297   dashboard at:  http://127.0.0.1:38977/status
INFO     distributed.scheduler:scheduler.py:8177 Registering Worker plugin shuffle
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:42477'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:44721'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:42675'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:38129'
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:36509 name: 1
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:36509
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:36564
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:34051 name: 0
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:34051
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:36574
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:43661 name: 2
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:43661
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:36590
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:37071 name: 3
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:37071
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:36592
INFO     distributed.scheduler:scheduler.py:5959 Receive client connection: MenrvaClient-2b56fbf1-5650-11f0-8966-6045bd7f8793
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:36598
INFO     distributed.scheduler:scheduler.py:8177 Registering Worker plugin worker_logger
INFO     viperlog:logger.py:55 Client <MenrvaClient: 'tcp://127.0.0.1:42659' processes=4 threads=4, memory=15.62 GiB>
INFO     distributed.scheduler:scheduler.py:7610 Retire worker addresses (stimulus_id='retire-workers-1751356280.7334273') (0, 1, 2, 3)
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:42477'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:44721'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:42675'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:38129'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:36574; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:34051 name: 0 (stimulus_id='handle-worker-cleanup-1751356280.7393692')
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:36564; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:36509 name: 1 (stimulus_id='handle-worker-cleanup-1751356280.7468994')
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:36592; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:37071 name: 3 (stimulus_id='handle-worker-cleanup-1751356280.7511418')
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:36590; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:43661 name: 2 (stimulus_id='handle-worker-cleanup-1751356280.755753')
INFO     distributed.scheduler:scheduler.py:5583 Lost all workers
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:42675' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:42477' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:38129' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:44721' closed.
INFO     distributed.scheduler:scheduler.py:4344 Closing scheduler. Reason: unknown
INFO     distributed.scheduler:scheduler.py:4372 Scheduler closing all comms