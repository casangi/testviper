INFO     viperlog:parameter.py:227 Module path: [38;2;50;50;205m/home/runner/work/testviper/testviper/src/toolviper[0m
WARNING  viperlog:logger.py:109 It is recommended that the local cache directory be set using the [38;2;50;50;205mdask_local_dir[0m parameter.
INFO     distributed.scheduler:scheduler.py:1766 State start
INFO     distributed.scheduler:scheduler.py:4282   Scheduler at:     tcp://127.0.0.1:45707
INFO     distributed.scheduler:scheduler.py:4297   dashboard at:  http://127.0.0.1:8787/status
INFO     distributed.scheduler:scheduler.py:8182 Registering Worker plugin shuffle
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:44931'
INFO     distributed.nanny:nanny.py:368         Start Nanny at: 'tcp://127.0.0.1:38667'
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:41665 name: 1
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:41665
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:37502
INFO     distributed.scheduler:scheduler.py:4635 Register worker addr: tcp://127.0.0.1:38225 name: 0
INFO     distributed.scheduler:scheduler.py:6224 Starting worker compute stream, tcp://127.0.0.1:38225
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:37514
INFO     distributed.scheduler:scheduler.py:5959 Receive client connection: MenrvaClient-771a2a6d-6e21-11f0-8a57-7c1e52cfc6b2
INFO     distributed.core:core.py:883 Starting established connection to tcp://127.0.0.1:37516
INFO     distributed.scheduler:scheduler.py:8182 Registering Worker plugin worker_logger
INFO     viperlog:logger.py:55 Client <MenrvaClient: 'tcp://127.0.0.1:45707' processes=2 threads=2, memory=14.90 GiB>
INFO     distributed.scheduler:scheduler.py:7615 Retire worker addresses (stimulus_id='retire-workers-1753975046.1967638') (0, 1)
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:44931'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.nanny:nanny.py:611 Closing Nanny at 'tcp://127.0.0.1:38667'. Reason: nanny-close
INFO     distributed.nanny:nanny.py:858 Nanny asking worker to close. Reason: nanny-close
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:37514; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:38225 name: 0 (stimulus_id='handle-worker-cleanup-1753975046.1995828')
INFO     distributed.core:core.py:908 Received 'close-stream' from tcp://127.0.0.1:37502; closing.
INFO     distributed.scheduler:scheduler.py:5445 Remove worker addr: tcp://127.0.0.1:41665 name: 1 (stimulus_id='handle-worker-cleanup-1753975046.2003229')
INFO     distributed.scheduler:scheduler.py:5583 Lost all workers
INFO     distributed.batched:batched.py:122 Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:45707 remote=tcp://127.0.0.1:37502>
Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.12.11/x64/lib/python3.12/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:44931' closed.
INFO     distributed.nanny:nanny.py:626 Nanny at 'tcp://127.0.0.1:38667' closed.
INFO     distributed.scheduler:scheduler.py:4344 Closing scheduler. Reason: unknown
INFO     distributed.scheduler:scheduler.py:4372 Scheduler closing all comms